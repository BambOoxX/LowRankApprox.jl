<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="LowRankApprox.jl : Fast low-rank matrix approximation in Julia">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>LowRankApprox.jl</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/klho/LowRankApprox.jl">View on GitHub</a>

          <h1 id="project_title">LowRankApprox.jl</h1>
          <h2 id="project_tagline">Fast low-rank matrix approximation in Julia</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/klho/LowRankApprox.jl/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/klho/LowRankApprox.jl/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="lowrankapprox" class="anchor" href="#lowrankapprox" aria-hidden="true"><span class="octicon octicon-link"></span></a>LowRankApprox</h1>

<p>This Julia package provides fast low-rank approximation algorithms for BLAS/LAPACK-compatible matrices based on some of the latest technology in adaptive randomized matrix sketching. Currently implemented algorithms include:</p>

<ul>
<li>sketch methods:

<ul>
<li>random Gaussian</li>
<li>random subset</li>
<li>subsampled random Fourier transform</li>
<li>sparse random Gaussian</li>
</ul>
</li>
<li>partial range finder</li>
<li>partial factorizations:

<ul>
<li>QR decomposition</li>
<li>interpolative decomposition</li>
<li>singular value decomposition</li>
<li>Hermitian eigendecomposition</li>
<li>CUR decomposition</li>
</ul>
</li>
<li>spectral norm estimation</li>
</ul>

<p>By "partial", we mean essentially that these algorithms are early-terminating, i.e., they are not simply post-truncated versions of their standard counterparts. There is also support for "matrix-free" linear operators described only through their action on vectors. All methods accept a number of options specifying, e.g., the rank, estimated absolute precision, and estimated relative precision of approximation.</p>

<p>Our implementation borrows heavily from the perspective espoused by <a href="http://dx.doi.org/10.1137/090771806">N. Halko, P.G. Martinsson, J.A. Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. SIAM Rev. 53 (2): 217-288, 2011.</a>, except that we choose the interpolative decomposition (ID) as our basic form of approximation instead of matrix range projection. The reason is that the latter requires expensive matrix-matrix multiplication to contract to the relevant subspace, while the former can sometimes be computed much faster, depending on the accelerated sketching strategy employed.</p>

<p>This package has been developed with performance in mind, and early tests have shown large speedups over similar codes written in MATLAB and Python (and even some in Fortran and C). For example, computing an ID of a Hilbert matrix of order 1024 to relative precision ~1e-15 takes:</p>

<ul>
<li>~0.02 s using LowRankApprox in Julia</li>
<li>~0.07 s using SciPy in Python (calling a Fortran backend; see <a href="http://klho.github.io/PyMatrixID">PyMatrixID</a>)</li>
<li>~0.3 s in MATLAB</li>
</ul>

<p>This difference can be attributed to Julia's tight integration with Fortran and C as well as to some low-level memory management not available in traditional dynamic languages.</p>

<p>LowRankApprox has been fully tested in Julia v0.4.0. The apparent build errors reported by Travis CI seem to be due to the reference 64-bit Julia installation being compiled against 32-bit BLAS.</p>

<h2>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installation</h2>

<p>To install LowRankApprox, simply type:</p>

<div class="highlight highlight-source-julia"><pre>Pkg<span class="pl-k">.</span><span class="pl-c1">clone</span>(<span class="pl-s"><span class="pl-pds">"</span>git://github.com/klho/LowRankApprox.jl.git<span class="pl-pds">"</span></span>)</pre></div>

<p>at the Julia prompt. The package can then be imported as usual with <code>using</code> or <code>import</code>.</p>

<h2>
<a id="getting-started" class="anchor" href="#getting-started" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting Started</h2>

<p>To illustrate the usage of this package, let's consider the computation of a partial QR decomposition of a Hilbert matrix, which is well known to have low rank. First, we load LowRankApprox via:</p>

<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> LowRankApprox</pre></div>

<p>Then we construct a Hilbert matrix with:</p>

<div class="highlight highlight-source-julia"><pre>n <span class="pl-k">=</span> <span class="pl-c1">1024</span>
A <span class="pl-k">=</span> <span class="pl-c1">matrixlib</span>(<span class="pl-c1">:hilb</span>, n, n)</pre></div>

<p>A partial QR decomposition can then be computed using:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(A)</pre></div>

<p>This returns a <code>PartialQR</code> factorization with variables <code>Q</code>, <code>R</code>, and <code>p</code> denoting the unitary, triangular, and permutation factors, respectively, constituting the decomposition. Alternatively, these can be extracted directly with:</p>

<div class="highlight highlight-source-julia"><pre>Q, R, p <span class="pl-k">=</span> <span class="pl-c1">pqr</span>(A)</pre></div>

<p>but the factorized form is often more convenient as it also implements various arithmetic operations. For example, the commands:</p>

<div class="highlight highlight-source-julia"><pre>x <span class="pl-k">=</span> <span class="pl-c1">rand</span>(n)
y <span class="pl-k">=</span> F <span class="pl-k">*</span>x
z <span class="pl-k">=</span> F<span class="pl-k">'</span><span class="pl-k">*</span>x</pre></div>

<p>automatically invoke specialized multiplication routines to rapidly compute <code>y</code> and <code>z</code> using the low-rank structure of <code>F</code>.</p>

<p>The rank of the factorization can be retrieved by <code>F[:k]</code>, which in this example usually gives 26 or 27. The reason for this variability is that the default interface uses randomized Gaussian sketching for acceleration. Likewise, the actual approximation error is also random but can be efficiently and robustly estimated:</p>

<div class="highlight highlight-source-julia"><pre>aerr <span class="pl-k">=</span> <span class="pl-c1">snormdiff</span>(A, F)
rerr <span class="pl-k">=</span> aerr <span class="pl-k">/</span> <span class="pl-c1">snorm</span>(A)</pre></div>

<p>This computes the absolute and relative errors in the spectral norm using power iteration. Here, the relative error achieved should be on the order of machine epsilon. (You may see a warning about exceeding the maximum number of iterations, but this is harmless in this case.)</p>

<p>The default interface requests ~1e-15 estimated relative precision. To request, say, only 1e-12 relative precision, use:</p>

<div class="highlight highlight-source-julia"><pre>rtol <span class="pl-k">=</span> <span class="pl-c1">1e-12</span>
F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(A, rtol)</pre></div>

<p>which returns a factorization of rank ~22. We can also directly control the rank instead with, e.g.:</p>

<div class="highlight highlight-source-julia"><pre>rank <span class="pl-k">=</span> <span class="pl-c1">20</span>
F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(A, rank)</pre></div>

<p>Both of these are variants of a single unified interface of the form:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(A, rank_or_rtol)</pre></div>

<p>which interprets <code>rank_or_rtol</code> as a relative precision if <code>rank_or_rtol &lt; 1</code> and as a rank otherwise.</p>

<p>The most general accuracy setting considers both the relative precision and the rank together, in addition to the absolute precision. For example, the code:</p>

<div class="highlight highlight-source-julia"><pre>opts <span class="pl-k">=</span> <span class="pl-c1">LRAOptions</span>(atol<span class="pl-k">=</span><span class="pl-c1">1e-9</span>, rank<span class="pl-k">=</span><span class="pl-c1">20</span>, rtol<span class="pl-k">=</span><span class="pl-c1">1e-12</span>)
F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(A, opts)</pre></div>

<p>sets three separate termination criteria: one on achieving estimated absolute precision 1e-9, another on achieving estimated relative precision 1e-12, and the last on reaching rank 20---with the computation completing upon any of these being fulfilled. Many other settings can also be specified through this "options" interface; we will discuss this in more detail later.</p>

<p>All of the above considerations also apply when the input is a linear operator, i.e., when the matrix is described not by its entries but by its action on vectors. To demonstrate, we can convert <code>A</code> to type <code>LinearOperator</code> as follows:</p>

<div class="highlight highlight-source-julia"><pre>L <span class="pl-k">=</span> <span class="pl-c1">LinearOperator</span>(A)</pre></div>

<p>which inherits and stores methods for applying the matrix and its adjoint. (This command actually recognizes <code>A</code> as Hermitian and forms <code>L</code> as a <code>HermitianLinearOperator</code>.) A partial QR decomposition can then be computed with:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(L)</pre></div>

<p>just as in the previous case. Of course, there is no real benefit to doing so in this particular example; the advantage comes when considering complicated matrix products that can be represented implicitly as a single <code>LinearOperator</code>. For instance, <code>A*A</code> can be represented as <code>L*L</code> without ever forming the resultant matrix explicitly, and we can even encapsulate entire factorizations as linear operators to exploit fast multiplication:</p>

<div class="highlight highlight-source-julia"><pre>L <span class="pl-k">=</span> <span class="pl-c1">LinearOperator</span>(F)</pre></div>

<p>Linear operators can be scaled, added, and composed together using the usual syntax. All methods in LowRankApprox transparently support both matrices and linear operators.</p>

<h2>
<a id="low-rank-factorizations" class="anchor" href="#low-rank-factorizations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Low-Rank Factorizations</h2>

<p>We now detail the various low-rank approximations implemented, which all nominally return compact <code>Factorization</code> types storing the matrix factors in structured form. All such factorizations provide optimized multiplication routines. Furthermore, the rank of any factorization <code>F</code> can be queried with <code>F[:k]</code> and the matrix approximant defined by <code>F</code> can be reconstructed as <code>full(F)</code>. For concreteness of exposition, assume in the following that <code>A</code> has size <code>m</code> by <code>n</code> with factorization rank <code>F[:k] = k</code>.</p>

<h3>
<a id="qr-decomposition" class="anchor" href="#qr-decomposition" aria-hidden="true"><span class="octicon octicon-link"></span></a>QR Decomposition</h3>

<p>A partial QR decomposition is a factorization <code>A[:,p] = Q*R</code>, where <code>Q</code> is <code>m</code> by <code>k</code> with orthonormal columns, <code>R</code> is <code>k</code> by <code>n</code> and upper trapezoidal, and <code>p</code> is a permutation vector. Such a decomposition can be computed with:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>or more explicitly with:</p>

<div class="highlight highlight-source-julia"><pre>Q, R, p <span class="pl-k">=</span> <span class="pl-c1">pqr</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>The former returns a <code>PartialQR</code> factorization with access methods:</p>

<ul>
<li>
<code>F[:Q]</code>: <code>Q</code> factor as type <code>Matrix</code>
</li>
<li>
<code>F[:R]</code>: <code>R</code> factor as type <code>UpperTrapezoidal</code>
</li>
<li>
<code>F[:p]</code>: <code>p</code> permutation as type <code>Vector</code>
</li>
<li>
<code>F[:P]</code>: <code>p</code> permutation as type <code>ColumnPermutation</code>
</li>
</ul>

<p>Both <code>F[:R]</code> and <code>F[:P]</code> are represented as structured matrices, complete with their own arithmetic operations, and together permit the alternate approximation formula <code>A*F[:P] = F[:Q]*F[:R]</code>. The factorization form additionally supports least squares solution by left-division.</p>

<p>We can also compute a partial QR decomposition of <code>A'</code> (that is, pivoting on rows instead of columns) without necessarily constructing the matrix transpose explicitly by writing:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(<span class="pl-c1">:c</span>, A, args<span class="pl-k">...</span>)</pre></div>

<p>and similarly with <code>pqr</code>. The default interface is equivalent to, e.g.:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">pqrfact</span>(<span class="pl-c1">:n</span>, A, args<span class="pl-k">...</span>)</pre></div>

<p>for "no transpose". It is also possible to generate only a subset of the partial QR factors for further efficiency; for details, see the <em>Options</em> section.</p>

<p>The above methods do not modify the input matrix <code>A</code> and may make a copy of the data in order to enforce this (whether this is necessary depends on the type of input and the sketch method used). Potentially more efficient versions that reserve the right to overwrite <code>A</code> are available as <code>pqrfact!</code> and <code>pqr!</code>, respectively.</p>

<h3>
<a id="interpolative-decomposition-id" class="anchor" href="#interpolative-decomposition-id" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interpolative Decomposition (ID)</h3>

<p>The ID is based on the approximation <code>A[:,rd] = A[:,sk]*T</code>, where <code>sk</code> is a set of <code>k</code> "skeleton" columns, <code>rd</code> is a set of <code>n - k</code> "redundant" columns, and <code>T</code> is a <code>k</code> by <code>n - k</code> interpolation matrix. It follows that <code>A[:,p] = C*V</code>, where <code>p = [sk; rd]</code>, <code>C = A[:,sk]</code>, and <code>V = [eye(k) T]</code>. An ID can be computed by:</p>

<div class="highlight highlight-source-julia"><pre>V <span class="pl-k">=</span> <span class="pl-c1">idfact</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>or:</p>

<div class="highlight highlight-source-julia"><pre>sk, rd, T <span class="pl-k">=</span> <span class="pl-c1">id</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>Here, <code>V</code> is of type <code>IDPackedV</code> and defines the <code>V</code> factor above but can also implicitly represent the entire ID via:</p>

<ul>
<li>
<code>V[:sk]</code>: <code>sk</code> columns as type <code>Vector</code>
</li>
<li>
<code>V[:rd]</code>: <code>rd</code> columns as type <code>Vector</code>
</li>
<li>
<code>V[:p]</code>: <code>p</code> permutation as type <code>Vector</code>
</li>
<li>
<code>V[:P]</code>: <code>p</code> permutation as type <code>ColumnPermutation</code>
</li>
<li>
<code>V[:T]</code>: <code>T</code> factor as type <code>Matrix</code>
</li>
</ul>

<p>To actually produce the ID itself, use:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">ID</span>(A, V)</pre></div>

<p>or:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">ID</span>(A, sk, rd, T)</pre></div>

<p>which returns an <code>ID</code> factorization that can be directly compared with <code>A</code>. This factorization has access methods:</p>

<ul>
<li>
<code>F[:C]</code>: <code>C</code> factor as type <code>Matrix</code>
</li>
<li>
<code>F[:V]</code>: <code>V</code> factor as type <code>IDPackedV</code>
</li>
</ul>

<p>in addition to those defined for <code>IDPackedV</code>.</p>

<p>As with the partial QR decomposition, an ID can be computed for <code>A'</code> instead (that is, finding skeleton rows as opposed to columns) in the same way, e.g.:</p>

<div class="highlight highlight-source-julia"><pre>V <span class="pl-k">=</span> <span class="pl-c1">idfact</span>(<span class="pl-c1">:c</span>, A, args<span class="pl-k">...</span>)</pre></div>

<p>The default interface is equivalent to passing <code>:n</code> as the first argument. Moreover, modifying versions of the above are available as <code>idfact!</code> and <code>id!</code>.</p>

<h3>
<a id="singular-value-decomposition-svd" class="anchor" href="#singular-value-decomposition-svd" aria-hidden="true"><span class="octicon octicon-link"></span></a>Singular Value Decomposition (SVD)</h3>

<p>A partial SVD is a factorization <code>A = U*S*V'</code>, where <code>U</code> and <code>V</code> are <code>m</code> by <code>k</code> and <code>n</code> by <code>k</code>, respectively, both with orthonormal columns, and <code>S</code> is <code>k</code> by <code>k</code> and diagonal with nonincreasing nonnegative real entries. It can be computed with:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">psvdfact</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>or:</p>

<div class="highlight highlight-source-julia"><pre>U, S, V <span class="pl-k">=</span> <span class="pl-c1">psvd</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>The factorization is of type <code>PartialSVD</code> and has access methods:</p>

<ul>
<li>
<code>F[:U]</code>: <code>U</code> factor as type <code>Matrix</code>
</li>
<li>
<code>F[:S]</code>: <code>S</code> factor as type <code>Vector</code>
</li>
<li>
<code>F[:V]</code>: <code>V</code> factor as type <code>Matrix</code>
</li>
<li>
<code>F[:Vt]</code>: <code>V'</code> factor as type <code>Matrix</code>
</li>
</ul>

<p>Note that the underlying SVD routine forms <code>V'</code> as output, so <code>F[:Vt]</code> is easier to extract than <code>F[:V]</code>. Least squares solution is also supported using left-division. Furthermore, if just the singular values are required, then we can use:</p>

<div class="highlight highlight-source-julia"><pre>S <span class="pl-k">=</span> <span class="pl-c1">psvdvals</span>(A, args<span class="pl-k">...</span>)</pre></div>

<h3>
<a id="hermitian-eigendecomposition" class="anchor" href="#hermitian-eigendecomposition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hermitian Eigendecomposition</h3>

<p>A partial Hermitian eigendecomposition of an <code>n</code> by <code>n</code> Hermitian matrix <code>A</code> is a factorization <code>A = U*S*U'</code>, where <code>U</code> is <code>n</code> by <code>k</code> with orthonormal columns and <code>S</code> is <code>k</code> by <code>k</code> and diagonal with nondecreasing real entries. It is very similar to a partial Hermitian SVD and can be computed by:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">pheigfact</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>or:</p>

<div class="highlight highlight-source-julia"><pre>values, vectors <span class="pl-k">=</span> <span class="pl-c1">pheig</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>where we have followed the Julia convention of letting <code>values</code> denote the eigenvalues comprising <code>S</code> and <code>vectors</code> denote the eigenvector matrix <code>U</code>. The factorization is of type <code>PartialHermitianEigen</code> and has access methods:</p>

<ul>
<li>
<code>F[:values]</code>: <code>values</code> as type <code>Vector</code>
</li>
<li>
<code>F[:vectors]</code>: <code>vectors</code> as type <code>Matrix</code>
</li>
</ul>

<p>It also supports least squares solution by left-division. If only the eigenvalues are desired, use instead:</p>

<div class="highlight highlight-source-julia"><pre>values <span class="pl-k">=</span> <span class="pl-c1">pheigvals</span>(A, args<span class="pl-k">...</span>)</pre></div>

<h3>
<a id="cur-decomposition" class="anchor" href="#cur-decomposition" aria-hidden="true"><span class="octicon octicon-link"></span></a>CUR Decomposition</h3>

<p>A CUR decomposition is a factorization <code>A = C*U*R</code>, where <code>C = A[:,cols]</code> and <code>R = A[rows,:]</code> consist of <code>k</code> columns and rows, respectively, from <code>A</code> and <code>U = inv(A[rows,cols])</code>. The basis rows and columns can be computed with:</p>

<div class="highlight highlight-source-julia"><pre>U <span class="pl-k">=</span> <span class="pl-c1">curfact</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>or:</p>

<div class="highlight highlight-source-julia"><pre>rows, cols <span class="pl-k">=</span> <span class="pl-c1">cur</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>The former is of type <code>CURPackedU</code> (or <code>HermitianCURPackedU</code> if <code>A</code> is Hermitian or <code>SymmetricCURPackedU</code> if symmetric) and has access methods:</p>

<ul>
<li>
<code>U[:cols]</code>: <code>cols</code> columns as type <code>Vector</code>
</li>
<li>
<code>U[:rows]</code>: <code>rows</code> rows as type <code>Vector</code>
</li>
</ul>

<p>To produce the corresponding CUR decomposition, use:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">CUR</span>(A, U)</pre></div>

<p>or:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">CUR</span>(A, rows, cols)</pre></div>

<p>which returns a <code>CUR</code> factorization (or <code>HermitianCUR</code> if <code>A</code> is Hermitian or <code>SymmetricCUR</code> if symmetric), with access methods:</p>

<ul>
<li>
<code>F[:C]</code>: <code>C</code> factor as type <code>Matrix</code>
</li>
<li>
<code>F[:U]</code>: <code>U</code> factor as type <code>Factorization</code>
</li>
<li>
<code>F[:R]</code>: <code>R</code> factor as type <code>Matrix</code>
</li>
</ul>

<p>in addition to those defined for <code>CURPackedU</code>. If <code>F</code> is of type <code>HermitianCUR</code>, then <code>F[:R] = F[:C]'</code>, while if <code>F</code> has type <code>SymmetricCUR</code>, then <code>F[:R] = F[:C].'</code>. Note that because of conditioning issues, <code>U</code> is not stored explicitly but rather in factored form, nominally as type <code>SVD</code> but practically as <code>PartialHermitianEigen</code> if <code>U</code> has type <code>HermitianCURPackedU</code> or <code>PartialSVD</code> otherwise (for convenient arithmetic operations).</p>

<p>Modifying versions of the above are available as <code>curfact!</code> and <code>cur!</code>.</p>

<h2>
<a id="sketch-methods" class="anchor" href="#sketch-methods" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sketch Methods</h2>

<p>Matrix sketching is a core component of this package and its proper use is critical for high performance. For an <code>m</code> by <code>n</code> matrix <code>A</code>, a sketch of order <code>k</code> takes the form <code>B = S*A</code>, where <code>S</code> is a <code>k</code> by <code>m</code> sampling matrix (see below). Sketches can similarly be constructed for sampling from the right or for multiplying against <code>A'</code>. The idea is that <code>B</code> contains a compressed representation of <code>A</code> up to rank approximately <code>k</code>, which can then be efficiently processed to recover information about <code>A</code>.</p>

<p>The default sketch method defines <code>S</code> as a Gaussian random matrix. Other sketch methods can be specified through the "options" interface. For example, setting:</p>

<div class="highlight highlight-source-julia"><pre>opts <span class="pl-k">=</span> <span class="pl-c1">LRAOptions</span>(sketch<span class="pl-k">=</span><span class="pl-c1">:srft</span>, args<span class="pl-k">...</span>)</pre></div>

<p>or equivalently:</p>

<div class="highlight highlight-source-julia"><pre>opts <span class="pl-k">=</span> <span class="pl-c1">LRAOptions</span>(args<span class="pl-k">...</span>)
opts<span class="pl-k">.</span>sketch <span class="pl-k">=</span> <span class="pl-c1">:srft</span></pre></div>

<p>then passing to, e.g.:</p>

<div class="highlight highlight-source-julia"><pre>V <span class="pl-k">=</span> <span class="pl-c1">idfact</span>(A, opts)</pre></div>

<p>computes an ID with sketching via a subsampled random Fourier transform (SRFT). A list of supported sketch methods is given below. To disable sketching altogether, use:</p>

<div class="highlight highlight-source-julia"><pre>opts<span class="pl-k">.</span>sketch <span class="pl-k">=</span> <span class="pl-c1">:none</span></pre></div>

<p>In addition to its integration with low-rank factorization methods, sketches can also be generated independently by:</p>

<div class="highlight highlight-source-julia"><pre>B <span class="pl-k">=</span> <span class="pl-c1">sketch</span>(A, order, opts)</pre></div>

<p>or simply:</p>

<div class="highlight highlight-source-julia"><pre>B <span class="pl-k">=</span> <span class="pl-c1">sketch</span>(A, order)</pre></div>

<p>to use the default options. Other interfaces include:</p>

<ul>
<li>
<code>B = sketch(:left, :n, A, order, args...)</code> to compute <code>B = S*A</code>
</li>
<li>
<code>B = sketch(:left, :c, A, order, args...)</code> to compute <code>B = S*A'</code>
</li>
<li>
<code>B = sketch(:right, :n, A, order, args...)</code> to compute <code>B = A*S</code>
</li>
<li>
<code>B = sketch(:right, :c, A, order, args...)</code> to compute <code>B = A'*S</code>
</li>
</ul>

<p>We also provide adaptive routines to automatically sketch with increasing orders until a specified error tolerance is met, as detected by early termination of an unaccelerated partial QR decomposition. This adaptive sketching forms the basis for essentially all higher-level algorithms in LowRankApprox and can be called with:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">sketchfact</span>(A, args<span class="pl-k">...</span>)</pre></div>

<p>where <code>args...</code> denotes either <code>rank_or_rtol</code> or <code>opts</code> as previously discussed. Like <code>sketch</code>, a more detailed interface is also available as:</p>

<div class="highlight highlight-source-julia"><pre>F <span class="pl-k">=</span> <span class="pl-c1">sketchfact</span>(side, trans, A, args<span class="pl-k">...</span>)</pre></div>

<p>where <code>side in (:left, :right)</code> and <code>trans in (:n, :c)</code>.</p>

<h3>
<a id="random-gaussian" class="anchor" href="#random-gaussian" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random Gaussian</h3>

<p>The canonical sampling matrix is a Gaussian random matrix with entries drawn independently from the standard normal distribution (or with real and imaginary parts each drawn independently if <code>A</code> is complex). To use this sketch method, set:</p>

<div class="highlight highlight-source-julia"><pre>opts<span class="pl-k">.</span>sketch <span class="pl-k">=</span> <span class="pl-c1">:randn</span></pre></div>

<p>There is also support for power iteration to improve accuracy when the spectral gap is small. This computes, e.g., <code>B = S*(A*A')^p*A</code> (or simply <code>B = S*A^(p + 1)</code> if <code>A</code> is Hermitian) instead of just <code>B = S*A</code>, with all intermediate matrix products orthogonalized for stability.</p>

<p>For generic <code>A</code>, Gaussian sketching has complexity <code>O(k*m*n)</code>. In principle, this makes it the most expensive stage of computing a fast low-rank approximation. There is thus a serious effort to develop sketch methods with lower computational cost, which is addressed in part by the following techniques.</p>

<h3>
<a id="random-subset" class="anchor" href="#random-subset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random Subset</h3>

<p>Perhaps the simplest matrix sketch is just a random subset of rows or columns, with complexity <code>O(k*m)</code> or <code>O(k*n)</code> as appropriate. This can be specified with:</p>

<div class="highlight highlight-source-julia"><pre>opts<span class="pl-k">.</span>sketch <span class="pl-k">=</span> <span class="pl-c1">:sub</span></pre></div>

<p>The linear growth in matrix dimension is obviously attractive, but note that this method can fail if the matrix is not sufficiently "regular", e.g., if it contains a few large isolated entries. Random subselection is only implemented for type <code>AbstractMatrix</code>.</p>

<h3>
<a id="subsampled-random-fourier-transform-srft" class="anchor" href="#subsampled-random-fourier-transform-srft" aria-hidden="true"><span class="octicon octicon-link"></span></a>Subsampled Random Fourier Transform (SRFT)</h3>

<p>An alternative approach based on imposing structure in the sampling matrix is the SRFT, which has the form <code>S = R*F*D</code> (if applying from the left), where <code>R</code> is a random permutation matrix of size <code>k</code> by <code>m</code>, <code>F</code> is the discrete Fourier transform (DFT) of order <code>m</code>, and <code>D</code> is a random diagonal unitary scaling. Due to the DFT structure, this can be applied in only <code>O(m*n*log(k))</code> operations. To use this method, set:</p>

<div class="highlight highlight-source-julia"><pre>opts<span class="pl-k">.</span>sketch <span class="pl-k">=</span> <span class="pl-c1">:srft</span></pre></div>

<p>For real <code>A</code>, our SRFT implementation uses only real arithmetic by separately computing real and imaginary parts as in a standard real-to-real DFT. Only <code>AbstractMatrix</code> types are supported.</p>

<h3>
<a id="sparse-random-gaussian" class="anchor" href="#sparse-random-gaussian" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sparse Random Gaussian</h3>

<p>As a modification of Gaussian sketching, we provide also a "sparse" random Gaussian sampling scheme, wherein <code>S</code> is restricted to have only <code>O(m)</code> or <code>O(n)</code> nonzeros, depending on the dimension to be contracted. Considering the case <code>B = S*A</code> for concreteness, each row of <code>S</code> is taken to be nonzero in only <code>O(m/k)</code> columns, with full coverage of <code>A</code> maintained by evenly spreading these nonzero indices among the rows of <code>S</code>. The complexity of computing <code>B</code> is <code>O(m*n)</code>. Sparse Gaussian sketching can be specified with:</p>

<div class="highlight highlight-source-julia"><pre>opts<span class="pl-k">.</span>sketch <span class="pl-k">=</span> <span class="pl-c1">:sprn</span></pre></div>

<p>and is only implemented for type <code>AbstractMatrix</code>. Power iteration is not supported since any subsequent matrix application would devolve back to having <code>O(k*m*n)</code> cost.</p>

<h2>
<a id="other-algorithms" class="anchor" href="#other-algorithms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other Algorithms</h2>

<h3>
<a id="partial-range" class="anchor" href="#partial-range" aria-hidden="true"><span class="octicon octicon-link"></span></a>Partial Range</h3>

<h3>
<a id="spectral-norm" class="anchor" href="#spectral-norm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Spectral Norm</h3>

<h2>
<a id="options" class="anchor" href="#options" aria-hidden="true"><span class="octicon octicon-link"></span></a>Options</h2>

<h2>
<a id="computational-complexity" class="anchor" href="#computational-complexity" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computational Complexity</h2>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">LowRankApprox.jl maintained by <a href="https://github.com/klho">klho</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
